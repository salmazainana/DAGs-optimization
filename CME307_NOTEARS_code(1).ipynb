{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import scipy.linalg as linalg\n",
        "import numpy as np\n",
        "!pip install igraph\n",
        "import igraph as ig\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FB4dMzPRTBd",
        "outputId": "4db1b684-a578-46e9-f328-c00016c531e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: igraph in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph) (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "jlKsY3veooo8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pTyuwvh7zYcW"
      },
      "outputs": [],
      "source": [
        "class NOTEARS:\n",
        "  def __init__(self, weight_threshold, max_rho, max_iter, h_tol, lambda1):\n",
        "    self.X = None\n",
        "    self.weight_threshold = weight_threshold\n",
        "    self.max_rho = max_rho\n",
        "    self.max_iter = max_iter\n",
        "    self.h_tol = h_tol\n",
        "    self.lambda1 = lambda1\n",
        "    self.rho = 1.0\n",
        "    self.alpha = 0.0\n",
        "    self.h = np.inf\n",
        "\n",
        "  def calc_h(self, W_flattened):\n",
        "    d = self.X.shape[1]\n",
        "    #W = W_flattened.reshape([d, d])\n",
        "    W = self._adj(W_flattened)\n",
        "    M = linalg.expm(W*W)\n",
        "    h = np.trace(M) - d\n",
        "    h_grad = 2* M.T * W\n",
        "    return h, h_grad\n",
        "\n",
        "\n",
        "  # Doesn't include regularization term\n",
        "  def objective_and_gradient(self, W_flattened):\n",
        "      d = self.X.shape[1]\n",
        "      n = self.X.shape[0]\n",
        "\n",
        "      #W = W_flattened.reshape([d, d])\n",
        "      W = self._adj(W_flattened)\n",
        "\n",
        "      # Just lasso regression loss\n",
        "      R = self.X - self.X @ W\n",
        "      loss = 1/(2*n) * (R**2).sum()\n",
        "      grad_loss = -1.0/n * self.X.T @ R\n",
        "      h, h_grad = self.calc_h(W_flattened)\n",
        "\n",
        "      #objective_value = loss + self.rho/2 * h**2 + self.alpha*h\n",
        "      #objective_gradient = grad_loss + (self.rho * h + self.alpha) * h_grad\n",
        "      #objective_gradient = np.concatenate((objective_gradient + self.lambda1, []), axis=None)\n",
        "\n",
        "      objective_value = loss + self.rho/2 * h**2 + self.alpha*h + self.lambda1*np.abs(W).sum()\n",
        "      objective_gradient = grad_loss + (self.rho * h + self.alpha) * h_grad\n",
        "      objective_gradient = np.concatenate((objective_gradient + self.lambda1, - objective_gradient + self.lambda1), axis=None)\n",
        "      return objective_value, objective_gradient\n",
        "\n",
        "  def _adj(self, w):\n",
        "        \"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"\n",
        "        # Note doubled variables are for handling non-smooth regularization term\n",
        "        return (w[:d * d] - w[d * d:]).reshape([d, d])\n",
        "\n",
        "\n",
        "  def solve(self):\n",
        "      d = self.X.shape[1]\n",
        "      n = self.X.shape[0]\n",
        "      # Starting guess for W; initialize rho, alpha\n",
        "      W_est_flattened, self.rho, self.alpha = np.zeros(2*d*d), 1.0, 0.0\n",
        "\n",
        "      # Set bounds for W_est matrix (basically diagonal elements must be zero.)\n",
        "      #bnds = [(0, 0) if i == j else (0, None) for i in range(d) for j in range(d)]\n",
        "      bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d) for j in range(d)]\n",
        "\n",
        "      # Perform Dual Gradient ascent to solve eq. (12) in paper\n",
        "      for i in range(1, self.max_iter, 1):\n",
        "          print(\"Iteration \" + str(i))\n",
        "\n",
        "          while self.rho < self.max_rho:\n",
        "              W_next_flattened = scipy.optimize.minimize(self.objective_and_gradient, W_est_flattened, method='L-BFGS-B', jac=True, bounds = bnds).x\n",
        "              #print(W_next_flattened)\n",
        "              h_next, _ = self.calc_h(W_next_flattened)\n",
        "              #print(h_next)\n",
        "              if h_next > 0.25*self.h: self.rho*= 10\n",
        "              else: break\n",
        "\n",
        "          W_est_flattened = W_next_flattened\n",
        "          self.h = h_next\n",
        "          self.alpha = self.alpha + self.rho*self.h\n",
        "          print(self.h)\n",
        "          #print(W_est_flattened.reshape([d, d]))\n",
        "\n",
        "          if self.h <= self.h_tol or self.rho >= self.max_rho: break\n",
        "\n",
        "      # Threshold values lower than weight_threshold (omega)\n",
        "      #W_est = W_est_flattened.reshape([d, d])\n",
        "      W_est = self._adj(W_est_flattened)\n",
        "      W_est[np.abs(W_est)< self.weight_threshold] = 0\n",
        "      assert self.is_dag(W_est)\n",
        "      np.savetxt('W_est.csv', W_est, delimiter=',')\n",
        "\n",
        "\n",
        "      accuracy = self.count_accuracy(B_true, W_est != 0)\n",
        "      print(accuracy)\n",
        "      return W_est\n",
        "\n",
        "\n",
        "  ### Helper functions to generate/simulate DAG (i.e. our synthetic data) (copied from NOTEARS code)\n",
        "  def is_dag(self, W):\n",
        "    G = ig.Graph.Weighted_Adjacency(W.tolist())\n",
        "    return G.is_dag()\n",
        "\n",
        "  def simulate_parameter(self, B, w_ranges=((-2.0, -0.5), (0.5, 2.0))):\n",
        "    \"\"\"Simulate SEM parameters for a DAG.\n",
        "\n",
        "    Args:\n",
        "        B (np.ndarray): [d, d] binary adj matrix of DAG\n",
        "        w_ranges (tuple): disjoint weight ranges\n",
        "\n",
        "    Returns:\n",
        "        W (np.ndarray): [d, d] weighted adj matrix of DAG\n",
        "    \"\"\"\n",
        "    W = np.zeros(B.shape)\n",
        "    S = np.random.randint(len(w_ranges), size=B.shape)  # which range\n",
        "    for i, (low, high) in enumerate(w_ranges):\n",
        "        U = np.random.uniform(low=low, high=high, size=B.shape)\n",
        "        W += B * (S == i) * U\n",
        "    return W\n",
        "\n",
        "\n",
        "  def simulate_dag(self, d, s0, graph_type):\n",
        "      \"\"\"Simulate random DAG with some expected number of edges.\n",
        "\n",
        "      Args:\n",
        "          d (int): num of nodes\n",
        "          s0 (int): expected num of edges\n",
        "          graph_type (str): ER, SF, BP\n",
        "\n",
        "      Returns:\n",
        "          B (np.ndarray): [d, d] binary adj matrix of DAG\n",
        "      \"\"\"\n",
        "      def _random_permutation(M):\n",
        "          # np.random.permutation permutes first axis only\n",
        "          P = np.random.permutation(np.eye(M.shape[0]))\n",
        "          return P.T @ M @ P\n",
        "\n",
        "      def _random_acyclic_orientation(B_und):\n",
        "          return np.tril(_random_permutation(B_und), k=-1)\n",
        "\n",
        "      def _graph_to_adjmat(G):\n",
        "          return np.array(G.get_adjacency().data)\n",
        "\n",
        "      if graph_type == 'ER':\n",
        "          # Erdos-Renyi\n",
        "          G_und = ig.Graph.Erdos_Renyi(n=d, m=s0)\n",
        "          B_und = _graph_to_adjmat(G_und)\n",
        "          B = _random_acyclic_orientation(B_und)\n",
        "      elif graph_type == 'SF':\n",
        "          # Scale-free, Barabasi-Albert\n",
        "          G = ig.Graph.Barabasi(n=d, m=int(round(s0 / d)), directed=True)\n",
        "          B = _graph_to_adjmat(G)\n",
        "      elif graph_type == 'BP':\n",
        "          # Bipartite, Sec 4.1 of (Gu, Fu, Zhou, 2018)\n",
        "          top = int(0.2 * d)\n",
        "          G = ig.Graph.Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n",
        "          B = _graph_to_adjmat(G)\n",
        "      else:\n",
        "          raise ValueError('unknown graph type')\n",
        "      B_perm = _random_permutation(B)\n",
        "      assert ig.Graph.Adjacency(B_perm.tolist()).is_dag()\n",
        "      return B_perm\n",
        "\n",
        "  def simulate_linear_sem(self, W, n, sem_type, noise_scale=None):\n",
        "      \"\"\"Simulate samples from linear SEM with specified type of noise.\n",
        "\n",
        "      For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n",
        "\n",
        "      Args:\n",
        "          W (np.ndarray): [d, d] weighted adj matrix of DAG\n",
        "          n (int): num of samples, n=inf mimics population risk\n",
        "          sem_type (str): gauss, exp, gumbel, uniform, logistic, poisson\n",
        "          noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n",
        "\n",
        "      Returns:\n",
        "          X (np.ndarray): [n, d] sample matrix, [d, d] if n=inf\n",
        "      \"\"\"\n",
        "      def _simulate_single_equation(X, w, scale):\n",
        "          \"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"\n",
        "          if sem_type == 'gauss':\n",
        "              z = np.random.normal(scale=scale, size=n)\n",
        "              x = X @ w + z\n",
        "          elif sem_type == 'exp':\n",
        "              z = np.random.exponential(scale=scale, size=n)\n",
        "              x = X @ w + z\n",
        "          elif sem_type == 'gumbel':\n",
        "              z = np.random.gumbel(scale=scale, size=n)\n",
        "              x = X @ w + z\n",
        "          elif sem_type == 'uniform':\n",
        "              z = np.random.uniform(low=-scale, high=scale, size=n)\n",
        "              x = X @ w + z\n",
        "          elif sem_type == 'logistic':\n",
        "              x = np.random.binomial(1, scipy.special.expit(X @ w)) * 1.0\n",
        "          elif sem_type == 'poisson':\n",
        "              x = np.random.poisson(np.exp(X @ w)) * 1.0\n",
        "          else:\n",
        "              raise ValueError('unknown sem type')\n",
        "          return x\n",
        "\n",
        "      d = W.shape[0]\n",
        "      if noise_scale is None:\n",
        "          scale_vec = np.ones(d)\n",
        "      elif np.isscalar(noise_scale):\n",
        "          scale_vec = noise_scale * np.ones(d)\n",
        "      else:\n",
        "          if len(noise_scale) != d:\n",
        "              raise ValueError('noise scale must be a scalar or has length d')\n",
        "          scale_vec = noise_scale\n",
        "      if not self.is_dag(W):\n",
        "          raise ValueError('W must be a DAG')\n",
        "      if np.isinf(n):  # population risk for linear gauss SEM\n",
        "          if sem_type == 'gauss':\n",
        "              # make 1/d X'X = true cov\n",
        "              X = np.sqrt(d) * np.diag(scale_vec) @ np.linalg.inv(np.eye(d) - W)\n",
        "              return X\n",
        "          else:\n",
        "              raise ValueError('population risk not available')\n",
        "      # empirical risk\n",
        "      G = ig.Graph.Weighted_Adjacency(W.tolist())\n",
        "      ordered_vertices = G.topological_sorting()\n",
        "      assert len(ordered_vertices) == d\n",
        "      X = np.zeros([n, d])\n",
        "      for j in ordered_vertices:\n",
        "          parents = G.neighbors(j, mode=ig.IN)\n",
        "          X[:, j] = _simulate_single_equation(X[:, parents], W[parents, j], scale_vec[j])\n",
        "      return X\n",
        "\n",
        "  def count_accuracy(self, B_true, B_est):\n",
        "    \"\"\"Compute various accuracy metrics for B_est.\n",
        "\n",
        "    true positive = predicted association exists in condition in correct direction\n",
        "    reverse = predicted association exists in condition in opposite direction\n",
        "    false positive = predicted association does not exist in condition\n",
        "\n",
        "    Args:\n",
        "        B_true (np.ndarray): [d, d] ground truth graph, {0, 1}\n",
        "        B_est (np.ndarray): [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG\n",
        "\n",
        "    Returns:\n",
        "        fdr: (reverse + false positive) / prediction positive\n",
        "        tpr: (true positive) / condition positive\n",
        "        fpr: (reverse + false positive) / condition negative\n",
        "        shd: undirected extra + undirected missing + reverse\n",
        "        nnz: prediction positive\n",
        "    \"\"\"\n",
        "    if (B_est == -1).any():  # cpdag\n",
        "        if not ((B_est == 0) | (B_est == 1) | (B_est == -1)).all():\n",
        "            raise ValueError('B_est should take value in {0,1,-1}')\n",
        "        if ((B_est == -1) & (B_est.T == -1)).any():\n",
        "            raise ValueError('undirected edge should only appear once')\n",
        "    else:  # dag\n",
        "        if not ((B_est == 0) | (B_est == 1)).all():\n",
        "            raise ValueError('B_est should take value in {0,1}')\n",
        "        if not self.is_dag(B_est):\n",
        "            raise ValueError('B_est should be a DAG')\n",
        "    d = B_true.shape[0]\n",
        "    # linear index of nonzeros\n",
        "    pred_und = np.flatnonzero(B_est == -1)\n",
        "    pred = np.flatnonzero(B_est == 1)\n",
        "    cond = np.flatnonzero(B_true)\n",
        "    cond_reversed = np.flatnonzero(B_true.T)\n",
        "    cond_skeleton = np.concatenate([cond, cond_reversed])\n",
        "    # true pos\n",
        "    true_pos = np.intersect1d(pred, cond, assume_unique=True)\n",
        "    # treat undirected edge favorably\n",
        "    true_pos_und = np.intersect1d(pred_und, cond_skeleton, assume_unique=True)\n",
        "    true_pos = np.concatenate([true_pos, true_pos_und])\n",
        "    # false pos\n",
        "    false_pos = np.setdiff1d(pred, cond_skeleton, assume_unique=True)\n",
        "    false_pos_und = np.setdiff1d(pred_und, cond_skeleton, assume_unique=True)\n",
        "    false_pos = np.concatenate([false_pos, false_pos_und])\n",
        "    # reverse\n",
        "    extra = np.setdiff1d(pred, cond, assume_unique=True)\n",
        "    reverse = np.intersect1d(extra, cond_reversed, assume_unique=True)\n",
        "    # compute ratio\n",
        "    pred_size = len(pred) + len(pred_und)\n",
        "    cond_neg_size = 0.5 * d * (d - 1) - len(cond)\n",
        "    fdr = float(len(reverse) + len(false_pos)) / max(pred_size, 1)\n",
        "    tpr = float(len(true_pos)) / max(len(cond), 1)\n",
        "    fpr = float(len(reverse) + len(false_pos)) / max(cond_neg_size, 1)\n",
        "    # structural hamming distance\n",
        "    pred_lower = np.flatnonzero(np.tril(B_est + B_est.T))\n",
        "    cond_lower = np.flatnonzero(np.tril(B_true + B_true.T))\n",
        "    extra_lower = np.setdiff1d(pred_lower, cond_lower, assume_unique=True)\n",
        "    missing_lower = np.setdiff1d(cond_lower, pred_lower, assume_unique=True)\n",
        "    shd = len(extra_lower) + len(missing_lower) + len(reverse)\n",
        "    return {'fdr': fdr, 'tpr': tpr, 'fpr': fpr, 'shd': shd, 'nnz': pred_size}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver = NOTEARS(weight_threshold= 0.3, max_rho= 1e16, max_iter= 100, h_tol= 1e-8, lambda1= 0.1)\n",
        "n, d, s0, graph_type, sem_type = 100, 20, 20, 'ER', 'gauss'\n",
        "solver.d = d\n",
        "B_true = solver.simulate_dag(d, s0, graph_type)\n",
        "W_true = solver.simulate_parameter(B_true)\n",
        "np.savetxt('W_true.csv', W_true, delimiter=',')\n",
        "\n",
        "solver.X = solver.simulate_linear_sem(W_true, n, sem_type)\n",
        "np.savetxt('X.csv', solver.X, delimiter=',')"
      ],
      "metadata": {
        "id": "ijIXY121rums"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "W_est = solver.solve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUjT7y5nJ-DM",
        "outputId": "4acd029a-bb2d-48c4-ceb9-696bd631abdd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "0.5802550103206379\n",
            "Iteration 2\n",
            "0.06588714391607198\n",
            "Iteration 3\n",
            "0.01574570932740471\n",
            "Iteration 4\n",
            "0.0036922952846865087\n",
            "Iteration 5\n",
            "0.0008590962515953038\n",
            "Iteration 6\n",
            "0.00020105388806612723\n",
            "Iteration 7\n",
            "4.515285115047618e-05\n",
            "Iteration 8\n",
            "1.0530318469648137e-05\n",
            "Iteration 9\n",
            "2.4660911286389364e-06\n",
            "Iteration 10\n",
            "6.13656943926344e-07\n",
            "Iteration 11\n",
            "9.794401378826478e-08\n",
            "Iteration 12\n",
            "1.384620418320992e-08\n",
            "Iteration 13\n",
            "2.0872334971500095e-09\n",
            "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 20}\n",
            "CPU times: user 4.17 s, sys: 4.25 s, total: 8.42 s\n",
            "Wall time: 7.07 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver.rho"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXLSIWDR-uYD",
        "outputId": "30e5a6f2-0879-4b21-bafc-e7975a32516d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000000000000.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver.alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnib7Y-IfjQ",
        "outputId": "4691f71a-5145-4d50-d9ef-23a9aba1f75a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3580251.95133044"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver.X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm1H27hsIhFO",
        "outputId": "f0a226ac-0563-4d2b-b55a-ac2a18c54380"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvMslEzLkwow"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}